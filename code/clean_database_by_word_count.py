#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“æ¸…ç†è„šæœ¬
åˆ é™¤word_countå­—æ®µå°äº15çš„æ•°æ®ï¼Œå¹¶å¯¹chunk_idè¿›è¡Œé‡æ–°ç¼–å·
"""

import chromadb
from chromadb.config import Settings
import os
from datetime import datetime
import json
import re

def clean_database_by_word_count():
    """
    æ¸…ç†æ•°æ®åº“ï¼šåˆ é™¤word_count < 15çš„æ•°æ®ï¼Œé‡æ–°ç¼–å·chunk_id
    """
    # ä¸»æ•°æ®åº“è·¯å¾„
    main_db_path = "e:\\PyProjects\\QASystem\\chroma_db"
    
    print(f"ğŸ§¹ å¼€å§‹æ¸…ç†æ•°æ®åº“: {main_db_path}")
    print(f"ğŸ“… æ¸…ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    if not os.path.exists(main_db_path):
        print(f"âŒ æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {main_db_path}")
        return False
    
    try:
        # è¿æ¥åˆ°ä¸»æ•°æ®åº“
        client = chromadb.PersistentClient(
            path=main_db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # è·å–qa_system_chunksé›†åˆ
        try:
            collection = client.get_collection("qa_system_chunks")
            print(f"âœ… æˆåŠŸè¿æ¥åˆ°é›†åˆ: qa_system_chunks")
        except Exception as e:
            print(f"âŒ æ— æ³•è·å–é›†åˆqa_system_chunks: {e}")
            return False
        
        # è·å–é›†åˆåŸºæœ¬ä¿¡æ¯
        original_count = collection.count()
        print(f"ğŸ“Š åŸå§‹æ–‡æ¡£æ€»æ•°: {original_count}")
        
        if original_count == 0:
            print("âš ï¸  é›†åˆä¸ºç©ºï¼Œæ²¡æœ‰æ–‡æ¡£éœ€è¦æ¸…ç†")
            return True
        
        # è·å–æ‰€æœ‰æ–‡æ¡£æ•°æ®
        print("ğŸ“¥ è·å–æ‰€æœ‰æ–‡æ¡£æ•°æ®...")
        all_results = collection.get(
            include=["documents", "metadatas", "embeddings"]
        )
        
        print(f"ğŸ“‹ è·å–åˆ° {len(all_results['documents'])} ä¸ªæ–‡æ¡£")
        
        # åˆ†æéœ€è¦åˆ é™¤çš„æ–‡æ¡£
        documents_to_keep = []
        metadatas_to_keep = []
        embeddings_to_keep = []
        ids_to_keep = []
        
        deleted_count = 0
        kept_count = 0
        
        print("ğŸ” åˆ†ææ–‡æ¡£ï¼Œç­›é€‰word_count >= 15çš„æ•°æ®...")
        
        for i, (doc_id, document, metadata, embedding) in enumerate(zip(
            all_results['ids'],
            all_results['documents'], 
            all_results['metadatas'],
            all_results['embeddings']
        )):
            # æ£€æŸ¥word_countå­—æ®µ
            word_count = metadata.get('word_count', 0) if metadata else 0
            
            # å¦‚æœword_countæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºæ•´æ•°
            if isinstance(word_count, str):
                try:
                    word_count = int(word_count)
                except ValueError:
                    word_count = 0
            
            # ä¿ç•™word_count >= 15çš„æ–‡æ¡£
            if word_count >= 15:
                documents_to_keep.append(document)
                metadatas_to_keep.append(metadata)
                embeddings_to_keep.append(embedding)
                ids_to_keep.append(doc_id)
                kept_count += 1
            else:
                deleted_count += 1
                if deleted_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªè¢«åˆ é™¤çš„æ–‡æ¡£ä¿¡æ¯
                    print(f"   ğŸ—‘ï¸  åˆ é™¤æ–‡æ¡£ {i+1}: word_count={word_count}, chunk_id={metadata.get('chunk_id', 'N/A') if metadata else 'N/A'}")
        
        print(f"\nğŸ“Š æ¸…ç†ç»Ÿè®¡:")
        print(f"   âœ… ä¿ç•™æ–‡æ¡£: {kept_count}")
        print(f"   ğŸ—‘ï¸  åˆ é™¤æ–‡æ¡£: {deleted_count}")
        
        if deleted_count == 0:
            print("âœ… æ²¡æœ‰éœ€è¦åˆ é™¤çš„æ–‡æ¡£ï¼Œæ•°æ®åº“å·²ç»æ˜¯å¹²å‡€çš„")
            return True
        
        # é‡æ–°ç¼–å·chunk_id
        print("\nğŸ”¢ é‡æ–°ç¼–å·chunk_id...")
        
        # æŒ‰sourceåˆ†ç»„é‡æ–°ç¼–å·
        source_counters = {}
        
        for i, metadata in enumerate(metadatas_to_keep):
            if metadata:
                source = metadata.get('source', 'unknown')
                
                # åˆå§‹åŒ–è®¡æ•°å™¨
                if source not in source_counters:
                    source_counters[source] = 0
                
                source_counters[source] += 1
                
                # ç”Ÿæˆæ–°çš„chunk_id
                if source.endswith('.txt'):
                    base_name = source[:-4]  # å»æ‰.txtåç¼€
                else:
                    base_name = source
                
                new_chunk_id = f"{base_name}-{source_counters[source]}"
                metadata['chunk_id'] = new_chunk_id
                
                # æ›´æ–°created_atæ—¶é—´æˆ³
                metadata['updated_at'] = datetime.now().isoformat()
        
        print(f"ğŸ“‹ é‡æ–°ç¼–å·å®Œæˆï¼Œå„æºæ–‡ä»¶ç»Ÿè®¡:")
        for source, count in source_counters.items():
            print(f"   ğŸ“„ {source}: {count} ä¸ªchunk")
        
        # å¤‡ä»½æ“ä½œç¡®è®¤
        print(f"\nâš ï¸  å³å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œ:")
        print(f"   ğŸ—‘ï¸  åˆ é™¤ {deleted_count} ä¸ªword_count < 15çš„æ–‡æ¡£")
        print(f"   ğŸ”¢ é‡æ–°ç¼–å· {kept_count} ä¸ªæ–‡æ¡£çš„chunk_id")
        print(f"   ğŸ’¾ æ›´æ–°æ•°æ®åº“")
        
        confirm = input("\nâ“ ç¡®è®¤æ‰§è¡Œæ¸…ç†æ“ä½œï¼Ÿ(è¾“å…¥ 'yes' ç¡®è®¤): ")
        if confirm.lower() != 'yes':
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return False
        
        # åˆ é™¤åŸé›†åˆ
        print("\nğŸ—‘ï¸  åˆ é™¤åŸé›†åˆ...")
        client.delete_collection("qa_system_chunks")
        
        # é‡æ–°åˆ›å»ºé›†åˆ
        print("ğŸ†• é‡æ–°åˆ›å»ºé›†åˆ...")
        new_collection = client.create_collection(
            name="qa_system_chunks",
            metadata={"description": "QA System document chunks with embeddings - cleaned"}
        )
        
        # ç”Ÿæˆæ–°çš„ID
        new_ids = [f"doc_{i+1}" for i in range(len(documents_to_keep))]
        
        # æ·»åŠ æ¸…ç†åçš„æ•°æ®
        print("ğŸ’¾ æ·»åŠ æ¸…ç†åçš„æ•°æ®...")
        if documents_to_keep:
            new_collection.add(
                ids=new_ids,
                documents=documents_to_keep,
                metadatas=metadatas_to_keep,
                embeddings=embeddings_to_keep
            )
        
        # éªŒè¯ç»“æœ
        final_count = new_collection.count()
        print(f"\nâœ… æ¸…ç†å®Œæˆ!")
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   ğŸ“„ åŸå§‹æ–‡æ¡£æ•°: {original_count}")
        print(f"   ğŸ—‘ï¸  åˆ é™¤æ–‡æ¡£æ•°: {deleted_count}")
        print(f"   ğŸ“„ æœ€ç»ˆæ–‡æ¡£æ•°: {final_count}")
        print(f"   ğŸ“ˆ æ•°æ®å‡å°‘: {((original_count - final_count) / original_count * 100):.1f}%")
        
        # ä¿å­˜æ¸…ç†æŠ¥å‘Š
        report_file = f"database_cleanup_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"æ•°æ®åº“æ¸…ç†æŠ¥å‘Š\n")
            f.write(f"æ¸…ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"åŸå§‹æ–‡æ¡£æ•°: {original_count}\n")
            f.write(f"åˆ é™¤æ–‡æ¡£æ•°: {deleted_count}\n")
            f.write(f"æœ€ç»ˆæ–‡æ¡£æ•°: {final_count}\n")
            f.write(f"æ•°æ®å‡å°‘: {((original_count - final_count) / original_count * 100):.1f}%\n\n")
            f.write("å„æºæ–‡ä»¶ç»Ÿè®¡:\n")
            for source, count in source_counters.items():
                f.write(f"  {source}: {count} ä¸ªchunk\n")
        
        print(f"ğŸ“„ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def preview_cleanup():
    """
    é¢„è§ˆæ¸…ç†æ“ä½œï¼Œä¸å®é™…æ‰§è¡Œåˆ é™¤
    """
    # ä¸»æ•°æ®åº“è·¯å¾„
    main_db_path = "e:\\PyProjects\\QASystem\\chroma_db"
    
    print(f"ğŸ‘€ é¢„è§ˆæ¸…ç†æ“ä½œ: {main_db_path}")
    print(f"ğŸ“… é¢„è§ˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    if not os.path.exists(main_db_path):
        print(f"âŒ æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {main_db_path}")
        return False
    
    try:
        # è¿æ¥åˆ°ä¸»æ•°æ®åº“
        client = chromadb.PersistentClient(
            path=main_db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # è·å–qa_system_chunksé›†åˆ
        collection = client.get_collection("qa_system_chunks")
        
        # è·å–æ‰€æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®
        all_results = collection.get(
            include=["metadatas"]
        )
        
        # ç»Ÿè®¡word_countåˆ†å¸ƒ
        word_count_stats = {}
        to_delete = []
        to_keep = []
        
        for i, metadata in enumerate(all_results['metadatas']):
            word_count = metadata.get('word_count', 0) if metadata else 0
            
            if isinstance(word_count, str):
                try:
                    word_count = int(word_count)
                except ValueError:
                    word_count = 0
            
            # ç»Ÿè®¡åˆ†å¸ƒ
            if word_count in word_count_stats:
                word_count_stats[word_count] += 1
            else:
                word_count_stats[word_count] = 1
            
            # åˆ†ç±»
            if word_count < 15:
                to_delete.append((i, word_count, metadata.get('chunk_id', 'N/A') if metadata else 'N/A'))
            else:
                to_keep.append((i, word_count, metadata.get('chunk_id', 'N/A') if metadata else 'N/A'))
        
        print(f"ğŸ“Š Word Count åˆ†å¸ƒç»Ÿè®¡:")
        for wc in sorted(word_count_stats.keys()):
            count = word_count_stats[wc]
            status = "ğŸ—‘ï¸ å°†åˆ é™¤" if wc < 15 else "âœ… ä¿ç•™"
            print(f"   word_count={wc}: {count} ä¸ªæ–‡æ¡£ {status}")
        
        print(f"\nğŸ“‹ æ¸…ç†é¢„è§ˆ:")
        print(f"   ğŸ—‘ï¸  å°†åˆ é™¤: {len(to_delete)} ä¸ªæ–‡æ¡£ (word_count < 15)")
        print(f"   âœ… å°†ä¿ç•™: {len(to_keep)} ä¸ªæ–‡æ¡£ (word_count >= 15)")
        
        if len(to_delete) > 0:
            print(f"\nğŸ—‘ï¸  å‰10ä¸ªå°†è¢«åˆ é™¤çš„æ–‡æ¡£:")
            for i, (doc_idx, wc, chunk_id) in enumerate(to_delete[:10]):
                print(f"   {i+1}. chunk_{doc_idx+1}: word_count={wc}, chunk_id={chunk_id}")
            
            if len(to_delete) > 10:
                print(f"   ... è¿˜æœ‰ {len(to_delete) - 10} ä¸ªæ–‡æ¡£å°†è¢«åˆ é™¤")
        
        return True
        
    except Exception as e:
        print(f"âŒ é¢„è§ˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    print("æ•°æ®åº“æ¸…ç†è„šæœ¬")
    print("1. é¢„è§ˆæ¸…ç†æ“ä½œ")
    print("2. æ‰§è¡Œæ¸…ç†æ“ä½œ")
    
    choice = input("è¯·é€‰æ‹©æ“ä½œ (1/2): ")
    
    if choice == "1":
        preview_cleanup()
    elif choice == "2":
        clean_database_by_word_count()
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")