# -*- coding: utf-8 -*-
"""
åˆ†æä¸»æ•°æ®åº“ä¸­qa_system_chunksé›†åˆçš„è¯¦ç»†ç»“æ„
è¯Šæ–­æŸ¥è¯¢é—®é¢˜çš„æ ¹æœ¬åŸå› 
"""

import chromadb
from chromadb.config import Settings
import os
from datetime import datetime
import json

def analyze_qa_system_chunks():
    """
    è¯¦ç»†åˆ†æqa_system_chunksé›†åˆçš„ç»“æ„
    """
    # ä¸»æ•°æ®åº“è·¯å¾„
    main_db_path = "e:\\PyProjects\\QASystem\\chroma_db"
    
    print(f"ğŸ” åˆ†æä¸»æ•°æ®åº“: {main_db_path}")
    print(f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    if not os.path.exists(main_db_path):
        print(f"âŒ ä¸»æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {main_db_path}")
        return False
    
    try:
        # è¿æ¥åˆ°ä¸»æ•°æ®åº“
        client = chromadb.PersistentClient(
            path=main_db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # è·å–qa_system_chunksé›†åˆ
        try:
            collection = client.get_collection("qa_system_chunks")
            print(f"âœ… æˆåŠŸè¿æ¥åˆ°é›†åˆ: qa_system_chunks")
        except Exception as e:
            print(f"âŒ æ— æ³•è·å–é›†åˆqa_system_chunks: {e}")
            return False
        
        # è·å–é›†åˆåŸºæœ¬ä¿¡æ¯
        count = collection.count()
        print(f"ğŸ“Š é›†åˆæ–‡æ¡£æ€»æ•°: {count}")
        print()
        
        if count == 0:
            print("âš ï¸  é›†åˆä¸ºç©ºï¼Œæ²¡æœ‰æ–‡æ¡£")
            return True
        
        # è·å–å‰5ä¸ªæ–‡æ¡£è¿›è¡Œè¯¦ç»†åˆ†æ
        print("ğŸ“‹ è·å–å‰5ä¸ªæ–‡æ¡£è¿›è¡Œç»“æ„åˆ†æ...")
        print("-" * 60)
        
        results = collection.get(
            limit=5,
            include=["documents", "metadatas"]
        )
        
        print(f"ğŸ” å®é™…è·å–åˆ°çš„æ–‡æ¡£æ•°é‡: {len(results['documents'])}")
        print()
        
        # åˆ†ææ¯ä¸ªæ–‡æ¡£çš„ç»“æ„
        for i, (document, metadata) in enumerate(zip(
            results['documents'], 
            results['metadatas']
        )):
            print(f"ğŸ“„ æ–‡æ¡£ {i+1}:")
            print(f"   ğŸ†” ID: [æ–‡æ¡£ç´¢å¼• {i}]")
            print(f"   ğŸ“ æ–‡æ¡£å†…å®¹é•¿åº¦: {len(document) if document else 0} å­—ç¬¦")
            
            # æ˜¾ç¤ºæ–‡æ¡£å†…å®¹çš„å‰100ä¸ªå­—ç¬¦
            if document:
                preview = document[:100] + "..." if len(document) > 100 else document
                print(f"   ğŸ“– å†…å®¹é¢„è§ˆ: {preview}")
            else:
                print(f"   ğŸ“– å†…å®¹é¢„è§ˆ: [ç©ºæ–‡æ¡£]")
            
            # è¯¦ç»†åˆ†æå…ƒæ•°æ®
            print(f"   ğŸ·ï¸  å…ƒæ•°æ®å­—æ®µæ•°é‡: {len(metadata) if metadata else 0}")
            if metadata:
                print(f"   ğŸ·ï¸  å…ƒæ•°æ®è¯¦æƒ…:")
                for key, value in metadata.items():
                    print(f"      - {key}: {value}")
            else:
                print(f"   ğŸ·ï¸  å…ƒæ•°æ®è¯¦æƒ…: [æ— å…ƒæ•°æ®]")
            
            print()
        
        # åˆ†ææ‰€æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®å­—æ®µç»Ÿè®¡
        print("ğŸ“Š å…ƒæ•°æ®å­—æ®µç»Ÿè®¡åˆ†æ...")
        print("-" * 60)
        
        # è·å–æ›´å¤šæ–‡æ¡£æ¥åˆ†æå…ƒæ•°æ®æ¨¡å¼
        all_results = collection.get(
            limit=min(100, count),  # æœ€å¤šåˆ†æ100ä¸ªæ–‡æ¡£
            include=["metadatas"]
        )
        
        # ç»Ÿè®¡å…ƒæ•°æ®å­—æ®µ
        field_counts = {}
        field_values = {}
        
        for metadata in all_results['metadatas']:
            if metadata:
                for key, value in metadata.items():
                    # ç»Ÿè®¡å­—æ®µå‡ºç°æ¬¡æ•°
                    field_counts[key] = field_counts.get(key, 0) + 1
                    
                    # æ”¶é›†å­—æ®µå€¼çš„æ ·æœ¬
                    if key not in field_values:
                        field_values[key] = set()
                    field_values[key].add(str(value))
        
        print(f"ğŸ“ˆ åˆ†æäº† {len(all_results['metadatas'])} ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®")
        print(f"ğŸ”‘ å‘ç°çš„å…ƒæ•°æ®å­—æ®µ:")
        
        for field, count in sorted(field_counts.items()):
            coverage = (count / len(all_results['metadatas'])) * 100
            sample_values = list(field_values[field])[:5]  # æ˜¾ç¤ºå‰5ä¸ªä¸åŒçš„å€¼
            
            print(f"   - {field}:")
            print(f"     ğŸ“Š å‡ºç°æ¬¡æ•°: {count}/{len(all_results['metadatas'])} ({coverage:.1f}%)")
            print(f"     ğŸ“ æ ·æœ¬å€¼: {sample_values}")
            if len(field_values[field]) > 5:
                print(f"     ğŸ“ (è¿˜æœ‰ {len(field_values[field]) - 5} ä¸ªä¸åŒå€¼...)")
            print()
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¸¸è§çš„æŸ¥è¯¢å­—æ®µ
        print("ğŸ” æŸ¥è¯¢ç›¸å…³å­—æ®µæ£€æŸ¥...")
        print("-" * 60)
        
        important_fields = ['source', 'chunk_type', 'chapter', 'section', 'document_type']
        
        for field in important_fields:
            if field in field_counts:
                print(f"âœ… å‘ç°é‡è¦å­—æ®µ '{field}': {field_counts[field]} ä¸ªæ–‡æ¡£åŒ…å«æ­¤å­—æ®µ")
                # æ˜¾ç¤ºè¯¥å­—æ®µçš„æ‰€æœ‰ä¸åŒå€¼
                unique_values = list(field_values[field])
                print(f"   ğŸ“‹ æ‰€æœ‰å€¼: {unique_values}")
            else:
                print(f"âŒ ç¼ºå°‘é‡è¦å­—æ®µ '{field}'")
            print()
        
        # æ£€æŸ¥æ–‡æ¡£å†…å®¹æ˜¯å¦ä¸ºç©º
        print("ğŸ“„ æ–‡æ¡£å†…å®¹æ£€æŸ¥...")
        print("-" * 60)
        
        content_results = collection.get(
            limit=min(50, count),
            include=["documents"]
        )
        
        empty_docs = 0
        short_docs = 0
        normal_docs = 0
        
        for document in content_results['documents']:
            if not document or len(document.strip()) == 0:
                empty_docs += 1
            elif len(document.strip()) < 50:
                short_docs += 1
            else:
                normal_docs += 1
        
        total_checked = len(content_results['documents'])
        print(f"ğŸ“Š æ–‡æ¡£å†…å®¹ç»Ÿè®¡ (æ£€æŸ¥äº† {total_checked} ä¸ªæ–‡æ¡£):")
        print(f"   ğŸ“„ æ­£å¸¸æ–‡æ¡£ (â‰¥50å­—ç¬¦): {normal_docs} ({(normal_docs/total_checked)*100:.1f}%)")
        print(f"   ğŸ“„ çŸ­æ–‡æ¡£ (<50å­—ç¬¦): {short_docs} ({(short_docs/total_checked)*100:.1f}%)")
        print(f"   ğŸ“„ ç©ºæ–‡æ¡£: {empty_docs} ({(empty_docs/total_checked)*100:.1f}%)")
        
        print()
        print("âœ… åˆ†æå®Œæˆ")
        
        # æä¾›è¯Šæ–­å»ºè®®
        print()
        print("ğŸ”§ è¯Šæ–­å»ºè®®:")
        print("-" * 60)
        
        if empty_docs > 0:
            print(f"âš ï¸  å‘ç° {empty_docs} ä¸ªç©ºæ–‡æ¡£ï¼Œè¿™å¯èƒ½å½±å“æŸ¥è¯¢ç»“æœ")
        
        if 'source' not in field_counts:
            print("âš ï¸  ç¼ºå°‘ 'source' å­—æ®µï¼Œè¿™å¯èƒ½å½±å“æŒ‰æ¥æºè¿‡æ»¤")
        
        if 'chunk_type' not in field_counts:
            print("âš ï¸  ç¼ºå°‘ 'chunk_type' å­—æ®µï¼Œè¿™å¯èƒ½å½±å“æŒ‰ç±»å‹è¿‡æ»¤")
        
        if field_counts:
            print("âœ… å…ƒæ•°æ®ç»“æ„çœ‹èµ·æ¥æ­£å¸¸")
        else:
            print("âŒ æ‰€æœ‰æ–‡æ¡£éƒ½ç¼ºå°‘å…ƒæ•°æ®ï¼Œè¿™ä¼šä¸¥é‡å½±å“æŸ¥è¯¢åŠŸèƒ½")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    analyze_qa_system_chunks()