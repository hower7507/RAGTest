# -*- coding: utf-8 -*-
"""
åˆ†æChromaDBä¸­çš„æ•°æ®æ ¼å¼å’Œé›†åˆåˆ†å¸ƒ
"""

import chromadb
import os
from collections import Counter

def analyze_chromadb_format():
    """
    åˆ†æChromaDBä¸­çš„æ•°æ®æ ¼å¼
    """
    print("=== ChromaDBæ•°æ®æ ¼å¼åˆ†æ ===")
    
    # ChromaDBé…ç½®
    db_path = "./chroma_db"
    
    try:
        # è¿æ¥ChromaDB
        print(f"è¿æ¥ChromaDB: {os.path.abspath(db_path)}")
        client = chromadb.PersistentClient(path=db_path)
        
        # åˆ—å‡ºæ‰€æœ‰é›†åˆ
        collections = client.list_collections()
        print(f"\næ€»é›†åˆæ•°: {len(collections)}")
        
        for collection in collections:
            print(f"\n{'='*60}")
            print(f"é›†åˆåç§°: {collection.name}")
            
            count = collection.count()
            print(f"æ–‡æ¡£æ€»æ•°: {count}")
            
            if count == 0:
                print("é›†åˆä¸ºç©º")
                continue
            
            # è·å–æ ·æœ¬æ•°æ®è¿›è¡Œåˆ†æ
            sample_size = min(50, count)
            sample = collection.get(
                limit=sample_size,
                include=["documents", "metadatas"]
            )
            
            # åˆ†ææ•°æ®æ¥æº
            source_files = []
            chunk_types = []
            
            for metadata in sample['metadatas']:
                source_file = metadata.get('source_file', 'unknown')
                chunk_type = metadata.get('chunk_type', 'unknown')
                source_files.append(source_file)
                chunk_types.append(chunk_type)
            
            # ç»Ÿè®¡æ¥æºæ–‡ä»¶
            source_counter = Counter(source_files)
            print("\nğŸ“ æ•°æ®æ¥æºåˆ†å¸ƒ:")
            for source, count in source_counter.most_common():
                print(f"  {source}: {count} ä¸ªæ–‡æ¡£")
            
            # ç»Ÿè®¡å—ç±»å‹
            type_counter = Counter(chunk_types)
            print("\nğŸ“Š æ•°æ®ç±»å‹åˆ†å¸ƒ:")
            for chunk_type, count in type_counter.most_common():
                print(f"  {chunk_type}: {count} ä¸ªæ–‡æ¡£")
            
            # æ˜¾ç¤ºç¤ºä¾‹æ–‡æ¡£
            print("\nğŸ“„ ç¤ºä¾‹æ–‡æ¡£:")
            for i in range(min(3, len(sample['ids']))):
                doc_id = sample['ids'][i]
                content = sample['documents'][i]
                metadata = sample['metadatas'][i]
                
                print(f"\n  æ–‡æ¡£ {i+1}:")
                print(f"    ID: {doc_id}")
                print(f"    æ¥æº: {metadata.get('source_file', 'N/A')}")
                print(f"    ç±»å‹: {metadata.get('chunk_type', 'N/A')}")
                print(f"    å†…å®¹: {content[:100]}...")
                
                # æ˜¾ç¤ºç‰¹å®šç±»å‹çš„å…ƒæ•°æ®
                chunk_type = metadata.get('chunk_type', '')
                if chunk_type == 'qa_pair':
                    print(f"    é—®é¢˜: {metadata.get('question', 'N/A')[:50]}...")
                    print(f"    ç­”æ¡ˆ: {metadata.get('answer', 'N/A')[:50]}...")
                elif chunk_type == 'traditional':
                    print(f"    æ—¶é—´: {metadata.get('start_time', 'N/A')} - {metadata.get('end_time', 'N/A')}")
                    print(f"    è¯´è¯äºº: {metadata.get('speakers', 'N/A')}")
                elif chunk_type == 'general_text':
                    print(f"    å­—æ•°: {metadata.get('word_count', 'N/A')}")
            
            # æ£€æŸ¥chap01å’Œchap02çš„åˆ†å¸ƒ
            print("\nğŸ” ç« èŠ‚æ•°æ®åˆ†æ:")
            chap01_count = sum(1 for sf in source_files if 'chap01' in sf.lower())
            chap02_count = sum(1 for sf in source_files if 'chap02' in sf.lower())
            
            print(f"  chap01ç›¸å…³æ–‡æ¡£: {chap01_count} ä¸ª")
            print(f"  chap02ç›¸å…³æ–‡æ¡£: {chap02_count} ä¸ª")
            
            if chap01_count > 0 and chap02_count > 0:
                print("  âœ… chap01å’Œchap02å­˜å‚¨åœ¨åŒä¸€ä¸ªé›†åˆä¸­")
            elif chap01_count > 0:
                print("  ğŸ“ åªæœ‰chap01æ•°æ®")
            elif chap02_count > 0:
                print("  ğŸ“ åªæœ‰chap02æ•°æ®")
            else:
                print("  âŒ æ²¡æœ‰æ‰¾åˆ°chap01æˆ–chap02æ•°æ®")
        
        # æ€»ç»“
        print(f"\n{'='*60}")
        print("ğŸ“‹ æ€»ç»“:")
        print(f"  - æ€»é›†åˆæ•°: {len(collections)}")
        if collections:
            main_collection = collections[0]
            total_docs = main_collection.count()
            print(f"  - ä¸»é›†åˆ: {main_collection.name}")
            print(f"  - æ€»æ–‡æ¡£æ•°: {total_docs}")
            
            # è·å–æ‰€æœ‰æ–‡æ¡£çš„æ¥æºç»Ÿè®¡
            if total_docs > 0:
                all_sample = main_collection.get(
                    limit=min(1000, total_docs),
                    include=["metadatas"]
                )
                all_sources = [m.get('source_file', 'unknown') for m in all_sample['metadatas']]
                all_source_counter = Counter(all_sources)
                
                chap01_total = sum(count for source, count in all_source_counter.items() if 'chap01' in source.lower())
                chap02_total = sum(count for source, count in all_source_counter.items() if 'chap02' in source.lower())
                
                print(f"  - chap01æ€»æ–‡æ¡£æ•°: {chap01_total}")
                print(f"  - chap02æ€»æ–‡æ¡£æ•°: {chap02_total}")
                
                if chap01_total > 0 and chap02_total > 0:
                    print("  âœ… chap01å’Œchap02ç¡®å®å­˜å‚¨åœ¨åŒä¸€ä¸ªé›†åˆä¸­")
                    
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """
    ä¸»å‡½æ•°
    """
    analyze_chromadb_format()

if __name__ == "__main__":
    main()