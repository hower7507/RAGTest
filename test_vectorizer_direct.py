# -*- coding: utf-8 -*-
"""
ç›´æ¥æµ‹è¯•å‘é‡åŒ–å™¨çš„æœç´¢åŠŸèƒ½
"""

import sys
import os
sys.path.append('e:\\PyProjects\\QASystem\\code')

from vectorize_chunks import ChunkVectorizer

def test_vectorizer_search():
    """ç›´æ¥æµ‹è¯•å‘é‡åŒ–å™¨æœç´¢åŠŸèƒ½"""
    
    print("=== ç›´æ¥æµ‹è¯•å‘é‡åŒ–å™¨æœç´¢åŠŸèƒ½ ===")
    
    try:
        # åˆ›å»ºå‘é‡åŒ–å™¨
        vectorizer = ChunkVectorizer(
            model_name="BAAI/bge-small-zh-v1.5",
            collection_name="qa_system_chunks"
        )
        
        # åŠ è½½æ¨¡å‹
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        vectorizer.load_model()
        
        # åˆå§‹åŒ–ChromaDB
        print("æ­£åœ¨åˆå§‹åŒ–ChromaDB...")
        vectorizer.init_chromadb("e:\\PyProjects\\QASystem\\chroma_db")
        
        # è·å–é›†åˆä¿¡æ¯
        info = vectorizer.get_collection_info()
        print(f"\næ•°æ®åº“ä¿¡æ¯:")
        print(f"  é›†åˆåç§°: {info.get('collection_name', 'unknown')}")
        print(f"  æ€»è®°å½•æ•°: {info.get('total_records', 0)}")
        print(f"  ç¤ºä¾‹ID: {info.get('sample_ids', [])[:5]}")
        
        if info.get('total_records', 0) == 0:
            print("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®")
            return False
        
        # æµ‹è¯•æœç´¢åŠŸèƒ½
        test_queries = [
            "è‡ªç„¶è¯­è¨€å¤„ç†",
            "æœºå™¨å­¦ä¹ ",
            "ä¸­å›½AIå‘å±•",
            "äººå·¥æ™ºèƒ½"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: '{query}'")
            
            try:
                # ä½¿ç”¨å‘é‡åŒ–å™¨æœç´¢
                results = vectorizer.search_similar_chunks(
                    query_text=query,
                    n_results=3
                )
                
                if results and 'documents' in results:
                    documents = results['documents'][0]
                    metadatas = results.get('metadatas', [[]])[0]
                    ids = results.get('ids', [[]])[0]
                    
                    print(f"  æ‰¾åˆ° {len(documents)} ä¸ªç»“æœ:")
                    
                    for i, (doc, metadata, doc_id) in enumerate(zip(documents, metadatas, ids)):
                        print(f"    ç»“æœ{i+1}:")
                        print(f"      ID: {doc_id}")
                        print(f"      å†…å®¹: {doc[:100]}...")
                        
                        if metadata:
                            # æ£€æŸ¥æ•°æ®æ¥æº
                            source = metadata.get('source', metadata.get('source_file', 'unknown'))
                            chunk_type = metadata.get('chunk_type', 'unknown')
                            print(f"      æ¥æº: {source}")
                            print(f"      ç±»å‹: {chunk_type}")
                            
                            if 'question' in metadata:
                                print(f"      é—®é¢˜: {metadata['question'][:50]}...")
                            if 'word_count' in metadata:
                                print(f"      å­—æ•°: {metadata['word_count']}")
                        else:
                            print(f"      å…ƒæ•°æ®: æ— ")
                        print()
                else:
                    print("  æœªæ‰¾åˆ°ç»“æœ")
                    
            except Exception as e:
                print(f"  æœç´¢å‡ºé”™: {e}")
        
        return True
        
    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_collection_data():
    """æµ‹è¯•é›†åˆä¸­çš„æ•°æ®åˆ†å¸ƒ"""
    
    print("\n=== æµ‹è¯•é›†åˆæ•°æ®åˆ†å¸ƒ ===")
    
    try:
        # åˆ›å»ºå‘é‡åŒ–å™¨
        vectorizer = ChunkVectorizer(
            model_name="BAAI/bge-small-zh-v1.5",
            collection_name="qa_system_chunks"
        )
        
        # åˆå§‹åŒ–ChromaDBï¼ˆä¸éœ€è¦åŠ è½½æ¨¡å‹ï¼‰
        vectorizer.init_chromadb("e:\\PyProjects\\QASystem\\chroma_db")
        
        # è·å–æ‰€æœ‰æ•°æ®
        all_data = vectorizer.collection.get(
            limit=1000,  # é™åˆ¶è·å–æ•°é‡
            include=["metadatas", "documents"]
        )
        
        total_count = len(all_data.get('metadatas', []))
        print(f"æ€»æ•°æ®é‡: {total_count}")
        
        if total_count == 0:
            print("âŒ é›†åˆä¸­æ²¡æœ‰æ•°æ®")
            return
        
        # ç»Ÿè®¡æ•°æ®åˆ†å¸ƒ
        chap01_count = 0
        chap02_count = 0
        other_count = 0
        qa_pair_count = 0
        
        for i, metadata in enumerate(all_data.get('metadatas', [])):
            if metadata:
                source = metadata.get('source', metadata.get('source_file', ''))
                chunk_type = metadata.get('chunk_type', '')
                
                if 'chap01' in str(source).lower():
                    chap01_count += 1
                elif 'chap02' in str(source).lower() or chunk_type == 'qa_pair':
                    chap02_count += 1
                    if chunk_type == 'qa_pair':
                        qa_pair_count += 1
                else:
                    other_count += 1
                    
                # æ˜¾ç¤ºå‰å‡ ä¸ªæ•°æ®çš„è¯¦ç»†ä¿¡æ¯
                if i < 5:
                    print(f"\nç¤ºä¾‹æ•°æ® {i+1}:")
                    print(f"  æ¥æº: {source}")
                    print(f"  ç±»å‹: {chunk_type}")
                    if 'question' in metadata:
                        print(f"  é—®é¢˜: {metadata['question'][:50]}...")
                    if 'word_count' in metadata:
                        print(f"  å­—æ•°: {metadata['word_count']}")
                    
                    # æ˜¾ç¤ºå†…å®¹ç‰‡æ®µ
                    documents = all_data.get('documents', [])
                    if i < len(documents):
                        content = documents[i]
                        print(f"  å†…å®¹: {content[:80]}...")
        
        print(f"\nğŸ“Š æ•°æ®åˆ†å¸ƒç»Ÿè®¡:")
        print(f"  chap01æ•°æ®: {chap01_count} ({(chap01_count/total_count)*100:.1f}%)")
        print(f"  chap02æ•°æ®: {chap02_count} ({(chap02_count/total_count)*100:.1f}%)")
        print(f"    å…¶ä¸­QAå¯¹: {qa_pair_count}")
        print(f"  å…¶ä»–æ•°æ®: {other_count} ({(other_count/total_count)*100:.1f}%)")
        
    except Exception as e:
        print(f"æµ‹è¯•é›†åˆæ•°æ®æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # æµ‹è¯•é›†åˆæ•°æ®åˆ†å¸ƒ
    test_collection_data()
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    test_vectorizer_search()