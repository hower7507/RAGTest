# -*- coding: utf-8 -*-
"""
æ£€æŸ¥æ•°æ®åº“ä¸­çš„å…ƒæ•°æ®ç»“æ„
"""

import sys
import os
sys.path.append('e:\\PyProjects\\QASystem\\code')

from vectorize_chunks import ChunkVectorizer

def check_metadata_structure():
    """æ£€æŸ¥æ•°æ®åº“ä¸­çš„å…ƒæ•°æ®ç»“æ„"""
    
    print("=== æ£€æŸ¥æ•°æ®åº“å…ƒæ•°æ®ç»“æ„ ===")
    
    try:
        # åˆå§‹åŒ–å‘é‡åŒ–å™¨
        vectorizer = ChunkVectorizer(
            model_name="BAAI/bge-small-zh-v1.5",
            collection_name="qa_system_chunks"
        )
        
        vectorizer.load_model()
        vectorizer.init_chromadb("e:\\PyProjects\\QASystem\\chroma_db")
        
        # è·å–é›†åˆä¿¡æ¯
        info = vectorizer.get_collection_info()
        print(f"é›†åˆåç§°: {info.get('collection_name', 'unknown')}")
        print(f"æ€»è®°å½•æ•°: {info.get('total_records', 0)}")
        
        # è·å–å‰10ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®
        print("\n=== å‰10ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®ç»“æ„ ===")
        
        sample_data = vectorizer.collection.get(
            limit=10,
            include=["metadatas", "documents"]
        )
        
        if sample_data and 'metadatas' in sample_data:
            metadatas = sample_data['metadatas']
            documents = sample_data.get('documents', [])
            
            for i, (metadata, doc) in enumerate(zip(metadatas, documents)):
                print(f"\n--- æ–‡æ¡£ {i+1} ---")
                print(f"å†…å®¹é•¿åº¦: {len(doc) if doc else 0}")
                print(f"å†…å®¹é¢„è§ˆ: {doc[:100] if doc else 'N/A'}...")
                
                if metadata:
                    print(f"å…ƒæ•°æ®é”®: {list(metadata.keys())}")
                    
                    # æ£€æŸ¥æ—¶é—´ç›¸å…³å­—æ®µ
                    time_fields = ['start_time', 'end_time', 'start_timestamp', 'end_timestamp']
                    print(f"æ—¶é—´å­—æ®µ:")
                    for field in time_fields:
                        if field in metadata:
                            print(f"  {field}: {metadata[field]} (ç±»å‹: {type(metadata[field])})")
                        else:
                            print(f"  {field}: ä¸å­˜åœ¨")
                    
                    # æ£€æŸ¥å…¶ä»–é‡è¦å­—æ®µ
                    other_fields = ['source', 'source_file', 'chunk_type', 'question', 'answer']
                    print(f"å…¶ä»–å­—æ®µ:")
                    for field in other_fields:
                        if field in metadata:
                            value = metadata[field]
                            if isinstance(value, str) and len(value) > 50:
                                value = value[:50] + "..."
                            print(f"  {field}: {value} (ç±»å‹: {type(metadata[field])})")
                        else:
                            print(f"  {field}: ä¸å­˜åœ¨")
                else:
                    print(f"å…ƒæ•°æ®: None")
        
        # ç»Ÿè®¡ä¸åŒç±»å‹çš„å…ƒæ•°æ®
        print("\n=== å…ƒæ•°æ®ç±»å‹ç»Ÿè®¡ ===")
        
        all_data = vectorizer.collection.get(
            limit=info.get('total_records', 1000),
            include=["metadatas"]
        )
        
        if all_data and 'metadatas' in all_data:
            metadatas = all_data['metadatas']
            
            # ç»Ÿè®¡å­—æ®µå‡ºç°é¢‘ç‡
            field_counts = {}
            time_field_counts = {}
            
            for metadata in metadatas:
                if metadata:
                    for key in metadata.keys():
                        field_counts[key] = field_counts.get(key, 0) + 1
                        
                        # ç‰¹åˆ«ç»Ÿè®¡æ—¶é—´å­—æ®µ
                        if key in ['start_time', 'end_time', 'start_timestamp', 'end_timestamp']:
                            time_field_counts[key] = time_field_counts.get(key, 0) + 1
            
            print(f"\næ‰€æœ‰å­—æ®µå‡ºç°é¢‘ç‡:")
            for field, count in sorted(field_counts.items()):
                percentage = (count / len(metadatas)) * 100
                print(f"  {field}: {count}/{len(metadatas)} ({percentage:.1f}%)")
            
            print(f"\næ—¶é—´å­—æ®µè¯¦ç»†ç»Ÿè®¡:")
            for field, count in sorted(time_field_counts.items()):
                percentage = (count / len(metadatas)) * 100
                print(f"  {field}: {count}/{len(metadatas)} ({percentage:.1f}%)")
            
            # æ£€æŸ¥æ—¶é—´å­—æ®µçš„å®é™…å€¼
            print(f"\næ—¶é—´å­—æ®µå€¼ç¤ºä¾‹:")
            for field in ['start_time', 'end_time', 'start_timestamp', 'end_timestamp']:
                values = []
                for metadata in metadatas[:20]:  # åªæ£€æŸ¥å‰20ä¸ª
                    if metadata and field in metadata:
                        values.append(metadata[field])
                
                if values:
                    print(f"  {field} ç¤ºä¾‹å€¼: {values[:5]}")
                    print(f"  {field} å€¼ç±»å‹: {[type(v) for v in values[:3]]}")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å…ƒæ•°æ®ç»“æ„å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ” å¼€å§‹æ£€æŸ¥æ•°æ®åº“å…ƒæ•°æ®ç»“æ„")
    print("=" * 60)
    
    check_metadata_structure()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ å…ƒæ•°æ®ç»“æ„æ£€æŸ¥å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    main()